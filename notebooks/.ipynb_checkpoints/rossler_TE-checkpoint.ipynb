{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Activating\u001b[22m\u001b[39m environment at `~/project_TE/package_CMI_prague/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg; Pkg.activate(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/project_TE/package_CMI_prague/Project.toml`\n",
      " \u001b[90m [5732040d] \u001b[39m\u001b[37mDelayEmbeddings v1.20.0\u001b[39m\n",
      " \u001b[90m [634d3b9d] \u001b[39m\u001b[37mDrWatson v1.16.6\u001b[39m\n",
      " \u001b[90m [ed8fcbec] \u001b[39m\u001b[37mEntropies v0.11.0 `https://github.com/JuliaDynamics/Entropies.jl#master`\u001b[39m\n",
      " \u001b[90m [d330b81b] \u001b[39m\u001b[37mPyPlot v2.9.0\u001b[39m\n",
      " \u001b[90m [fd094767] \u001b[39m\u001b[37mSuppressor v0.2.0\u001b[39m\n",
      " \u001b[90m [79125185] \u001b[39m\u001b[37mpackage_CMI_prague v0.1.0 `src/package_CMI_prague`\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tranfserentropy (generic function with 6 methods)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../src/read_bin.jl\")\n",
    "include(\"../src/basicent.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using Suppressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.0\n",
      "2 0.002551020408163265\n",
      "3 0.00510204081632653\n",
      "4 0.007653061224489796\n",
      "5 0.01020408163265306\n",
      "6 0.012755102040816325\n",
      "7 0.015306122448979591\n",
      "8 0.017857142857142856\n",
      "9 0.02040816326530612\n",
      "10 0.02295918367346939\n",
      "11 0.02551020408163265\n",
      "12 0.02806122448979592\n",
      "13 0.030612244897959183\n",
      "14 0.033163265306122444\n",
      "15 0.03571428571428571\n",
      "16 0.03826530612244898\n",
      "17 0.04081632653061224\n",
      "18 0.04336734693877551\n",
      "19 0.04591836734693878\n",
      "20 0.04846938775510204\n",
      "21 0.0510204081632653\n",
      "22 0.053571428571428575\n",
      "23 0.05612244897959184\n",
      "24 0.0586734693877551\n",
      "25 0.061224489795918366\n",
      "26 0.06377551020408162\n",
      "27 0.06632653061224489\n",
      "28 0.06887755102040817\n",
      "29 0.07142857142857142\n",
      "30 0.07397959183673469\n",
      "31 0.07653061224489796\n",
      "32 0.07908163265306122\n",
      "33 0.08163265306122448\n",
      "34 0.08418367346938775\n",
      "35 0.08673469387755102\n",
      "36 0.08928571428571429\n",
      "37 0.09183673469387756\n",
      "38 0.09438775510204081\n",
      "39 0.09693877551020408\n",
      "40 0.09948979591836735\n",
      "41 0.1020408163265306\n",
      "42 0.10459183673469387\n",
      "43 0.10714285714285715\n",
      "44 0.1096938775510204\n",
      "45 0.11224489795918367\n",
      "46 0.11479591836734694\n",
      "47 0.1173469387755102\n",
      "48 0.11989795918367346\n",
      "49 0.12244897959183673\n",
      "50 0.125\n",
      "51 0.12755102040816324\n",
      "52 0.13010204081632654\n",
      "53 0.13265306122448978\n",
      "54 0.13520408163265304\n",
      "55 0.13775510204081634\n",
      "56 0.14030612244897958\n",
      "57 0.14285714285714285\n",
      "58 0.14540816326530612\n",
      "59 0.14795918367346939\n",
      "60 0.15051020408163263\n",
      "61 0.15306122448979592\n",
      "62 0.1556122448979592\n",
      "63 0.15816326530612243\n",
      "64 0.16071428571428573\n",
      "65 0.16326530612244897\n",
      "66 0.16581632653061223\n",
      "67 0.1683673469387755\n",
      "68 0.17091836734693877\n",
      "69 0.17346938775510204\n",
      "70 0.1760204081632653\n",
      "71 0.17857142857142858\n",
      "72 0.18112244897959182\n",
      "73 0.1836734693877551\n",
      "74 0.18622448979591835\n",
      "75 0.18877551020408162\n",
      "76 0.19132653061224492\n",
      "77 0.19387755102040816\n",
      "78 0.19642857142857142\n",
      "79 0.1989795918367347\n",
      "80 0.20153061224489796\n",
      "81 0.2040816326530612\n",
      "82 0.2066326530612245\n",
      "83 0.20918367346938774\n",
      "84 0.211734693877551\n",
      "85 0.2142857142857143\n",
      "86 0.21683673469387754\n",
      "87 0.2193877551020408\n",
      "88 0.22193877551020408\n",
      "89 0.22448979591836735\n",
      "90 0.2270408163265306\n",
      "91 0.22959183673469388\n",
      "92 0.23214285714285715\n",
      "93 0.2346938775510204\n",
      "94 0.2372448979591837\n",
      "95 0.23979591836734693\n",
      "96 0.2423469387755102\n",
      "97 0.24489795918367346\n",
      "98 0.24744897959183673\n"
     ]
    }
   ],
   "source": [
    "n_points = 131072\n",
    "couplings = LinRange(0, 0.25, 99)\n",
    "root = \"../data/exp_raw/binfiles/Rossler_bin_\"\n",
    "#root = \"/Users/andreu/Desktop/Dropbox/transfer_inormation_prague/code/binfiles/Rossler_bin_\"\n",
    "test_couplings = read_bin_couplings(root, n_points, couplings);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DrWatson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Distributions: Uniform, Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3056091842771398\n",
      "1.0909453959501931\n"
     ]
    }
   ],
   "source": [
    "a = test_couplings[:,:,33]\n",
    "x = a[:,2]/maximum(abs.(a[:,2]))\n",
    "Bin = 3\n",
    "estKnn = Kraskov(w = 3, k = Bin)\n",
    "estVf  = VisitationFrequency(Entropies.RectangularBinning(Bin))\n",
    "E1 = Entropies.genentropy(Dataset(x), estKnn)\n",
    "E2 = Entropies.genentropy(Dataset(x), estVf)\n",
    "println(E1)\n",
    "println(E2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TE_for_couplings (generic function with 3 methods)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Overly complex function that computes mean tranfer entropy (TE) for a dataset consisting in N sets\n",
    "of pairs of becots dependent on a correlation coefficient e. For each pair the TE is computed for τ lags\n",
    "and the mean of these lags is stored. There are  N such pairs and only 1 in n are computed,\n",
    "by default n = 10. The value of the mean TE is stored in a text file of a given name\"\"\"\n",
    "\n",
    "function TE_for_couplings(test_couplings, τs, js, est, τ_range, root2, name, n = 10)\n",
    "    TE = Array{Float64}(undef,  length(couplings), 1)\n",
    "    @suppress_err begin\n",
    "    open(\"$root2/$name\", \"w\") do f\n",
    "        for i in 1:size(test_couplings, 3)-1\n",
    "            if i%n == 3\n",
    "                mean_TE = 0\n",
    "                a = test_couplings[:,:,i]\n",
    "                x = a[:,1]#/maximum(abs.(a[:,1]))\n",
    "                y = a[:,2]#/maximum(abs.(a[:,2]))\n",
    "                for t in τ_range\n",
    "                    print(t)\n",
    "                    ts =  changevector!(τs, t, length(τs))\n",
    "                    joint = DelayEmbeddings.genembed(Dataset(x, y),  τs, js )\n",
    "                    #e = tranfserentropy(joint, est; embdim = 5, α =1.0, base =2)\n",
    "                    e = tranfserentropy(joint, est,  2)              \n",
    "                    mean_TE += e/length(τ_range) \n",
    "                    TE[i] = e\n",
    "                end\n",
    "                println(i, \" , \", couplings[i], ' ', mean_TE)\n",
    "                aux = couplings[i]\n",
    "                write(f, \"$aux $mean_TE\\n\")\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    end\n",
    "end       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Int64,1}:\n",
       "  0\n",
       " 11\n",
       " 20"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "τs = (0,  0, 20)\n",
    "changevector!(τs, 11, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name_of_file (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function name_of_file(est, Bin, maxτ, τs, js)\n",
    "    strEst = string(est)[1:3]\n",
    "    prefix = \"couplings_TE\"\n",
    "    suffix = \"txt\"\n",
    "    \n",
    "    tsjs = '_'\n",
    "    for (i, e) in enumerate(τs)\n",
    "        tsjs = string(τs[length(τs)-i+1], tsjs, js[i])\n",
    "    end\n",
    "    \n",
    "    #name = \"$prefix-$strEst-$Bin-lag_$lag.$suffix\"\n",
    "    d = (est = strEst,  Bin = Bin, maxlag = maxτ, tsjs = tsjs  )\n",
    "    name = savename(prefix, d , suffix)\n",
    "    println(name)\n",
    "    return name\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access (1, 2, 2)\n  at index [4]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access (1, 2, 2)\n  at index [4]",
      "",
      "Stacktrace:",
      " [1] getindex at ./tuple.jl:24 [inlined]",
      " [2] name_of_file(::Kraskov, ::Int64, ::Int64, ::NTuple{5,Int64}, ::Tuple{Int64,Int64,Int64}) at ./In[20]:8",
      " [3] top-level scope at In[29]:22",
      " [4] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "Bin = 3\n",
    "b = Entropies.RectangularBinning(Bin)\n",
    "root2 = \"../data/exp_pro/correlations_TE\"\n",
    "lag = 25\n",
    "maxτ = 50\n",
    "jumpτ = 5\n",
    "intervalsτ = 10\n",
    "\n",
    "aux = LinRange(jumpτ, maxτ, intervalsτ)\n",
    "τ_range = round.(Int64, aux)\n",
    "\n",
    "#τs = (0,  -10, -5, 0, maxτ)\n",
    "τs = (0,  0, maxτ)\n",
    "\n",
    "#est = VisitationFrequency(b)\n",
    "#est = KozachenkoLeonenko(RecBin,0)\n",
    "#est = KozachenkoLeonenko(w = 0)\n",
    "est = Kraskov(w = Bin, k = Bin)\n",
    "\n",
    "js = (1, 2, 2)\n",
    "#js = (1, 2, 2, 2, 2)\n",
    "name = name_of_file(est, Bin, maxτ, τs, js)\n",
    "TE_for_couplings(test_couplings, τs, js, est, τ_range, root2, name)\n",
    "\n",
    "js = (2, 1, 1)\n",
    "#js = (2, 1, 1, 1, 1)\n",
    "name = name_of_file(est, Bin, maxτ, τs, js)\n",
    "TE_for_couplings(test_couplings, τs, js, est, τ_range, root2, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: mean_TE not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: mean_TE not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[27]:1",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "plot(couplings, mean_TE)\n",
    "xlabel!(\"Coupling ϵ\")\n",
    "ylabel!(\"TE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "changevector! (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"this is a stupid function that given a vector A, copies it \n",
    "to a vector B but changes  one unique value of that vector \n",
    "in the position I, leaving all ther rest the same\"\"\"\n",
    "\n",
    "function changevector!(A, τ, I)\n",
    "    B = Vector{Int64}(undef, length(A))#zeros(length(A))\n",
    "     # LinRange(0, 0, length(A))#A#Array{Tuple{Int64,Int64}}(undef, length(couplings))\n",
    "    @inbounds for i in eachindex(A)\n",
    "        if i == I\n",
    "            #append!( B, τ )\n",
    "            B[i] = τ\n",
    "        else\n",
    "            #append!( B, A[i] )\n",
    "            B[i] = A[i]\n",
    "        end\n",
    "    end\n",
    "    return B\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
      "5  uh "
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access (-13.45701, 2.652757, -3.878211)\n  at index [5]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access (-13.45701, 2.652757, -3.878211)\n  at index [5]",
      "",
      "Stacktrace:",
      " [1] getindex at ./tuple.jl:24 [inlined]",
      " [2] getindex at /Users/andreu/.julia/packages/StaticArrays/NTbHj/src/SVector.jl:40 [inlined]",
      " [3] getindex at /Users/andreu/.julia/packages/DelayEmbeddings/Jcztf/src/dataset.jl:40 [inlined]",
      " [4] getindex(::Dataset{3,Float64}, ::UnitRange{Int64}, ::Array{Int64,1}) at /Users/andreu/.julia/packages/DelayEmbeddings/Jcztf/src/dataset.jl:64",
      " [5] getindex at /Users/andreu/.julia/packages/DelayEmbeddings/Jcztf/src/dataset.jl:72 [inlined]",
      " [6] tranfserentropy(::Dataset{3,Float64}, ::KozachenkoLeonenko, ::Int64, ::Int64) at /Users/andreu/project_TE/package_CMI_prague/src/basicent.jl:96",
      " [7] tranfserentropy(::Dataset{3,Float64}, ::KozachenkoLeonenko, ::Int64) at /Users/andreu/project_TE/package_CMI_prague/src/basicent.jl:94",
      " [8] macro expansion at ./In[74]:35 [inlined]",
      " [9] macro expansion at /Users/andreu/.julia/packages/Suppressor/nTjgZ/src/Suppressor.jl:98 [inlined]",
      " [10] (::var\"#145#147\")(::IOStream) at ./In[74]:23",
      " [11] open(::var\"#145#147\", ::String, ::Vararg{String,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at ./io.jl:325",
      " [12] open(::Function, ::String, ::String) at ./io.jl:323",
      " [13] top-level scope at In[74]:22",
      " [14] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "#root2 = \"/Users/andreu/Desktop/Dropbox/transfer_inormation_prague/code/correlations_TE\"\n",
    "root2 = \"../data/exp_pro/correlations_TE\"\n",
    "maxτ = 50\n",
    "jumpτ = 5\n",
    "aux = LinRange(jumpτ, maxτ, 10)\n",
    "τ_range = round.(Int64, aux)\n",
    "println(τ_range)\n",
    "#τs = (0,  10, 5, 0, maxτ)\n",
    "#js = (2, 1, 1, 1, 1)\n",
    "#js = (1, 2, 2, 2, 2)\n",
    "\n",
    "τs = (0, 0,  maxτ ) #RIGhT ORDER FOR THE 3 dimensional embbeding case\n",
    "#js = (2, 1, 1)\n",
    "js = (1, 2, 2)\n",
    "\n",
    "aux = '_'\n",
    "for (i, e) in enumerate(τs)\n",
    "    aux = string(τs[length(τs)-i+1],aux,js[i])\n",
    "end\n",
    "name = \"couplings_meanTE_Knn$RecBin-$aux.txt\"\n",
    "\n",
    "open(\"$root2/$name\", \"w\") do f\n",
    "    @suppress_err begin\n",
    "        for i in 1:size(test_couplings, 3)-1\n",
    "            mean_TE = 0\n",
    "            a = test_couplings[:,:,i]\n",
    "            x = a[:,1]\n",
    "            y = a[:,2]\n",
    "            for t in τ_range\n",
    "                print(t)\n",
    "                ts =  changevector!(τs, t, length(τs))\n",
    "                joint = DelayEmbeddings.genembed(Dataset(x, y),  ts, js )\n",
    "                #e = tranfserentropy(joint, VisitationFrequency(b), α = 1.0, base = 2)\n",
    "                #e = tranfserentropy(joint, VisitationFrequency(b); embdim = 5, α =1.0, base =2)\n",
    "                e = tranfserentropy(joint, KozachenkoLeonenko(1,8),  2)\n",
    "                mean_TE += e/length(τ_range)  \n",
    "            end\n",
    "            aux = couplings[i]\n",
    "            println(couplings[i], ' ', mean_TE)\n",
    "            write(f, \"$aux $mean_TE\\n\")\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Int64,1}:\n",
       "  3\n",
       "  6\n",
       "  9\n",
       " 12\n",
       " 15\n",
       " 18\n",
       " 21\n",
       " 24\n",
       " 27\n",
       " 30"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = LinRange(jumpτ, maxτ, 10)\n",
    "τ_range = round.(Int64, aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "τ_range = LinRange(1, 10, 10)\n",
    "EE = Array{Float64}(undef,  length(τ_range), 1)\n",
    "for t in τ_range\n",
    "    EE[1] += t/length(τ_range) #+ EE[1] \n",
    "end\n",
    "EE[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " 3.0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = zeros(0)#LinRange(0, 0, length(τs))\n",
    "append!( B, 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Int64,1}:\n",
       "   0\n",
       "  33\n",
       "   0\n",
       "  -5\n",
       " -10"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts =  changevector!(τs, 33, 2)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "genembed(s, τs, js = ones(...); ws = nothing) → dataset\n",
       "\\end{verbatim}\n",
       "Create a generalized embedding of \\texttt{s} which can be a timeseries or arbitrary \\texttt{Dataset}, and return the result as a new \\texttt{Dataset}.\n",
       "\n",
       "The generalized embedding works as follows:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{τs} denotes what delay times will be used for each of the entries of the delay vector. It is recommended that \\texttt{τs[1] = 0}. \\texttt{τs} is allowed to have \\emph{negative entries} as well.\n",
       "\n",
       "\n",
       "\\item \\texttt{js} denotes which of the timeseries contained in \\texttt{s} will be used for the entries of the delay vector. \\texttt{js} can contain duplicate indices.\n",
       "\n",
       "\n",
       "\\item \\texttt{ws} are optional weights that weight each embedded entry (the i-th entry of the    delay vector is weighted by \\texttt{ws[i]}). If provided, it is recommended that \\texttt{ws[1] = 1}\n",
       "\n",
       "\\end{itemize}\n",
       "\\texttt{τs, js, ws} are tuples (or vectors) of length \\texttt{D}, which also coincides with the embedding dimension. For example, imagine input trajectory $s = [x, y, z]$ where $x, y, z$ are timeseries (the columns of the \\texttt{Dataset}). If \\texttt{js = (1, 3, 2)} and \\texttt{τs = (0, 2, -7)} the created delay vector at each step $n$ will be\n",
       "\n",
       "$$(x(n), z(n+2), y(n-7))$$\n",
       "Using \\texttt{ws = (1, 0.5, 0.25)} as well would create\n",
       "\n",
       "$$(x(n), \\frac{1}{2} z(n+2), \\frac{1}{4} y(n-7))$$\n",
       "\\texttt{js} can be skipped, defaulting to index 1 (first timeseries) for all delay entries, while it has no effect if \\texttt{s} is a timeseries instead of a \\texttt{Dataset}.\n",
       "\n",
       "See also \\href{@ref}{\\texttt{embed}}. Internally uses \\href{@ref}{\\texttt{GeneralizedEmbedding}}.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "genembed(s, τs, js = ones(...); ws = nothing) → dataset\n",
       "```\n",
       "\n",
       "Create a generalized embedding of `s` which can be a timeseries or arbitrary `Dataset`, and return the result as a new `Dataset`.\n",
       "\n",
       "The generalized embedding works as follows:\n",
       "\n",
       "  * `τs` denotes what delay times will be used for each of the entries of the delay vector. It is recommended that `τs[1] = 0`. `τs` is allowed to have *negative entries* as well.\n",
       "  * `js` denotes which of the timeseries contained in `s` will be used for the entries of the delay vector. `js` can contain duplicate indices.\n",
       "  * `ws` are optional weights that weight each embedded entry (the i-th entry of the    delay vector is weighted by `ws[i]`). If provided, it is recommended that `ws[1] = 1`\n",
       "\n",
       "`τs, js, ws` are tuples (or vectors) of length `D`, which also coincides with the embedding dimension. For example, imagine input trajectory $s = [x, y, z]$ where $x, y, z$ are timeseries (the columns of the `Dataset`). If `js = (1, 3, 2)` and `τs = (0, 2, -7)` the created delay vector at each step $n$ will be\n",
       "\n",
       "$$\n",
       "(x(n), z(n+2), y(n-7))\n",
       "$$\n",
       "\n",
       "Using `ws = (1, 0.5, 0.25)` as well would create\n",
       "\n",
       "$$\n",
       "(x(n), \\frac{1}{2} z(n+2), \\frac{1}{4} y(n-7))\n",
       "$$\n",
       "\n",
       "`js` can be skipped, defaulting to index 1 (first timeseries) for all delay entries, while it has no effect if `s` is a timeseries instead of a `Dataset`.\n",
       "\n",
       "See also [`embed`](@ref). Internally uses [`GeneralizedEmbedding`](@ref).\n"
      ],
      "text/plain": [
       "\u001b[36m  genembed(s, τs, js = ones(...); ws = nothing) → dataset\u001b[39m\n",
       "\n",
       "  Create a generalized embedding of \u001b[36ms\u001b[39m which can be a timeseries or arbitrary\n",
       "  \u001b[36mDataset\u001b[39m, and return the result as a new \u001b[36mDataset\u001b[39m.\n",
       "\n",
       "  The generalized embedding works as follows:\n",
       "\n",
       "    •    \u001b[36mτs\u001b[39m denotes what delay times will be used for each of the entries\n",
       "        of the delay vector. It is recommended that \u001b[36mτs[1] = 0\u001b[39m. \u001b[36mτs\u001b[39m is\n",
       "        allowed to have \u001b[4mnegative entries\u001b[24m as well.\n",
       "\n",
       "    •    \u001b[36mjs\u001b[39m denotes which of the timeseries contained in \u001b[36ms\u001b[39m will be used for\n",
       "        the entries of the delay vector. \u001b[36mjs\u001b[39m can contain duplicate indices.\n",
       "\n",
       "    •    \u001b[36mws\u001b[39m are optional weights that weight each embedded entry (the i-th\n",
       "        entry of the delay vector is weighted by \u001b[36mws[i]\u001b[39m). If provided, it\n",
       "        is recommended that \u001b[36mws[1] = 1\u001b[39m\n",
       "\n",
       "  \u001b[36mτs, js, ws\u001b[39m are tuples (or vectors) of length \u001b[36mD\u001b[39m, which also coincides with\n",
       "  the embedding dimension. For example, imagine input trajectory \u001b[35ms = [x, y, z]\u001b[39m\n",
       "  where \u001b[35mx, y, z\u001b[39m are timeseries (the columns of the \u001b[36mDataset\u001b[39m). If \u001b[36mjs = (1, 3, 2)\u001b[39m\n",
       "  and \u001b[36mτs = (0, 2, -7)\u001b[39m the created delay vector at each step \u001b[35mn\u001b[39m will be\n",
       "\n",
       "\u001b[35m  (x(n), z(n+2), y(n-7))\u001b[39m\n",
       "\n",
       "  Using \u001b[36mws = (1, 0.5, 0.25)\u001b[39m as well would create\n",
       "\n",
       "\u001b[35m  (x(n), \\frac{1}{2} z(n+2), \\frac{1}{4} y(n-7))\u001b[39m\n",
       "\n",
       "  \u001b[36mjs\u001b[39m can be skipped, defaulting to index 1 (first timeseries) for all delay\n",
       "  entries, while it has no effect if \u001b[36ms\u001b[39m is a timeseries instead of a \u001b[36mDataset\u001b[39m.\n",
       "\n",
       "  See also \u001b[36membed\u001b[39m. Internally uses \u001b[36mGeneralizedEmbedding\u001b[39m."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?DelayEmbeddings.genembed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_couplings[1,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a1 = test_couplings[:,:,1]\n",
    "x1 = a1[:,1]\n",
    "y1 = a1[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint= DelayEmbeddings.genembed(Dataset(x1, y1),  (0,0,1), (1,2,2) );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RectangularBinning(50)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = RectangularBinning(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "genentropy(p::Probabilities; α = 1.0, base = Base.MathConstants.e)\n",
       "\\end{verbatim}\n",
       "Compute the generalized order-\\texttt{α} entropy of some probabilities returned by the \\href{@ref}{\\texttt{probabilities}} function. Alternatively, compute entropy from pre-computed \\texttt{Probabilities}.\n",
       "\n",
       "\\subsection{Description}\n",
       "Let $p$ be an array of probabilities (summing to 1). Then the generalized (Rényi) entropy is\n",
       "\n",
       "$$H_\\alpha(p) = \\frac{1}{1-\\alpha} \\log \\left(\\sum_i p[i]^\\alpha\\right)$$\n",
       "and generalizes other known entropies, like e.g. the information entropy ($\\alpha = 1$, see \\footnotemark[Shannon1948]), the maximum entropy ($\\alpha=0$, also known as Hartley entropy), or the correlation entropy ($\\alpha = 2$, also known as collision entropy).\n",
       "\n",
       "\\begin{verbatim}\n",
       "genentropy(x::Vector_or_Dataset, est; α = 1.0, base)\n",
       "\\end{verbatim}\n",
       "A convenience syntax, which calls first \\texttt{probabilities(x, est)} and then calculates the entropy of the result (and thus \\texttt{est} can be a \\texttt{ProbabilitiesEstimator} or simply \\texttt{ε::Real}).\n",
       "\n",
       "\\footnotetext[Rényi1960]{A. Rényi, \\emph{Proceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability}, pp 547 (1960)\n",
       "\n",
       "}\n",
       "\\footnotetext[Shannon1948]{C. E. Shannon, Bell Systems Technical Journal \\textbf{27}, pp 379 (1948)\n",
       "\n",
       "}\n"
      ],
      "text/markdown": [
       "```\n",
       "genentropy(p::Probabilities; α = 1.0, base = Base.MathConstants.e)\n",
       "```\n",
       "\n",
       "Compute the generalized order-`α` entropy of some probabilities returned by the [`probabilities`](@ref) function. Alternatively, compute entropy from pre-computed `Probabilities`.\n",
       "\n",
       "## Description\n",
       "\n",
       "Let $p$ be an array of probabilities (summing to 1). Then the generalized (Rényi) entropy is\n",
       "\n",
       "$$\n",
       "H_\\alpha(p) = \\frac{1}{1-\\alpha} \\log \\left(\\sum_i p[i]^\\alpha\\right)\n",
       "$$\n",
       "\n",
       "and generalizes other known entropies, like e.g. the information entropy ($\\alpha = 1$, see [^Shannon1948]), the maximum entropy ($\\alpha=0$, also known as Hartley entropy), or the correlation entropy ($\\alpha = 2$, also known as collision entropy).\n",
       "\n",
       "```\n",
       "genentropy(x::Vector_or_Dataset, est; α = 1.0, base)\n",
       "```\n",
       "\n",
       "A convenience syntax, which calls first `probabilities(x, est)` and then calculates the entropy of the result (and thus `est` can be a `ProbabilitiesEstimator` or simply `ε::Real`).\n",
       "\n",
       "[^Rényi1960]: A. Rényi, *Proceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability*, pp 547 (1960)\n",
       "\n",
       "[^Shannon1948]: C. E. Shannon, Bell Systems Technical Journal **27**, pp 379 (1948)\n"
      ],
      "text/plain": [
       "\u001b[36m  genentropy(p::Probabilities; α = 1.0, base = Base.MathConstants.e)\u001b[39m\n",
       "\n",
       "  Compute the generalized order-\u001b[36mα\u001b[39m entropy of some probabilities returned by\n",
       "  the \u001b[36mprobabilities\u001b[39m function. Alternatively, compute entropy from pre-computed\n",
       "  \u001b[36mProbabilities\u001b[39m.\n",
       "\n",
       "\u001b[1m  Description\u001b[22m\n",
       "\u001b[1m  =============\u001b[22m\n",
       "\n",
       "  Let \u001b[35mp\u001b[39m be an array of probabilities (summing to 1). Then the generalized\n",
       "  (Rényi) entropy is\n",
       "\n",
       "\u001b[35m  H_\\alpha(p) = \\frac{1}{1-\\alpha} \\log \\left(\\sum_i p[i]^\\alpha\\right)\u001b[39m\n",
       "\n",
       "  and generalizes other known entropies, like e.g. the information entropy\n",
       "  (\u001b[35m\\alpha = 1\u001b[39m, see \u001b[1m[^Shannon1948]\u001b[22m), the maximum entropy (\u001b[35m\\alpha=0\u001b[39m, also known\n",
       "  as Hartley entropy), or the correlation entropy (\u001b[35m\\alpha = 2\u001b[39m, also known as\n",
       "  collision entropy).\n",
       "\n",
       "\u001b[36m  genentropy(x::Vector_or_Dataset, est; α = 1.0, base)\u001b[39m\n",
       "\n",
       "  A convenience syntax, which calls first \u001b[36mprobabilities(x, est)\u001b[39m and then\n",
       "  calculates the entropy of the result (and thus \u001b[36mest\u001b[39m can be a\n",
       "  \u001b[36mProbabilitiesEstimator\u001b[39m or simply \u001b[36mε::Real\u001b[39m).\n",
       "\n",
       "  │ \u001b[0m\u001b[1m[^Rényi1960]\u001b[22m\n",
       "  │\n",
       "  │  A. Rényi, \u001b[4mProceedings of the fourth Berkeley Symposium on\n",
       "  │  Mathematics, Statistics and Probability\u001b[24m, pp 547 (1960)\n",
       "\n",
       "  │ \u001b[0m\u001b[1m[^Shannon1948]\u001b[22m\n",
       "  │\n",
       "  │  C. E. Shannon, Bell Systems Technical Journal \u001b[1m27\u001b[22m, pp 379 (1948)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?Entropies.genentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07771054563072077"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = tranfserentropy(joint, VisitationFrequency(b),  1.0, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
